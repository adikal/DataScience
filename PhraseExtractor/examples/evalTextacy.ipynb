{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['5.0 out of 5 stars']</td>\n",
       "      <td>['Love alexa']</td>\n",
       "      <td>[\"It's very useful but wish she could do more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['5.0 out of 5 stars']</td>\n",
       "      <td>['Great asset to the home']</td>\n",
       "      <td>['Love it. New to smart technology for the hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['5.0 out of 5 stars']</td>\n",
       "      <td>['Great product']</td>\n",
       "      <td>['Works great for an alarm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['5.0 out of 5 stars']</td>\n",
       "      <td>['Awesome little office companion!']</td>\n",
       "      <td>['I absolutely love my echo dot. Being able to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['3.0 out of 5 stars']</td>\n",
       "      <td>[\"It's wifi reception sucks more rear and a ri...</td>\n",
       "      <td>['\"Sorry I\\'m having trouble understanding rig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rating                                              title  \\\n",
       "0  ['5.0 out of 5 stars']                                     ['Love alexa']   \n",
       "1  ['5.0 out of 5 stars']                        ['Great asset to the home']   \n",
       "2  ['5.0 out of 5 stars']                                  ['Great product']   \n",
       "3  ['5.0 out of 5 stars']               ['Awesome little office companion!']   \n",
       "4  ['3.0 out of 5 stars']  [\"It's wifi reception sucks more rear and a ri...   \n",
       "\n",
       "                                                body  \n",
       "0  [\"It's very useful but wish she could do more ...  \n",
       "1  ['Love it. New to smart technology for the hom...  \n",
       "2                       ['Works great for an alarm']  \n",
       "3  ['I absolutely love my echo dot. Being able to...  \n",
       "4  ['\"Sorry I\\'m having trouble understanding rig...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import textacy\n",
    "import textacy.keyterms\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "data_df = pd.read_csv('../data/amazon_echo_10pgs.csv')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_review( review,stop_words=False,stemmer=False,lemma=False):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # Remove HTML\n",
    "    words = BeautifulSoup(review,\"lxml\").get_text()\n",
    "\n",
    "    words = re.sub(\"'\",\". \", words) \n",
    "    \n",
    "\n",
    "    #  \n",
    "    # Remove non-letters and , and .\n",
    "    words = re.sub(\"[^a-zA-Z,.]\",\" \", words) \n",
    "    #\n",
    "    \n",
    "    #return\n",
    "    nomarkup  = words\n",
    "\n",
    "    # Convert words to lower case and split them\n",
    "    #words= words.lower()\n",
    "    \n",
    "    if lemma:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = lemmatizer.lemmatize(words)\n",
    "        \n",
    "    #tokenize\n",
    "    words = words.split()\n",
    "    #\n",
    "    # .remove punctuation from each word\n",
    "    #table = str.maketrans('', '', string.punctuation)\n",
    "    #words = [w.translate(table) for w in words]\n",
    "\n",
    "    # Optionally remove stop words (false by default)\n",
    "    if stop_words:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "\n",
    "    #stemming of words\n",
    "    if stemmer:\n",
    "        porter = PorterStemmer()\n",
    "        words = [porter.stem(word) for word in words]\n",
    "\n",
    "   \n",
    "\n",
    "    clean_review = \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in words]).strip()\n",
    "    \n",
    "    #Create spacy doc\n",
    "    #doc = nlp(clean_review)\n",
    "    \n",
    "    \n",
    "    #for token in doc:\n",
    "     #   print(token.text, token.pos_, token.tag_, token.dep_)\n",
    "    #for chunk in doc.noun_chunks:\n",
    "     #   if (re.match('[a-zA-Z]+\\s+[a-zA-Z]+',chunk.text)):\n",
    "      #      print (chunk.text)\n",
    "          \n",
    "    return(clean_review,nomarkup)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = \"\"\n",
    "neg_reviews = \"\"\n",
    "\n",
    "#Iterate through dataframe of reviews.\n",
    "#Each row is a review\n",
    "for index,row  in data_df.iterrows():\n",
    "    #Check for positive or negative review\n",
    "    clean_review,nomarkup_review = cleanup_review(row.body)\n",
    "\n",
    "    #Create overall group of positive and negative reviews\n",
    "    if (re.search('(4|5).0 out of.*',row.rating)) : \n",
    "        pos_reviews = pos_reviews + \" \" + clean_review\n",
    "        pos_reviews =  re.sub('\\.\\s*\\.','.',pos_reviews)\n",
    "    else : \n",
    "        neg_reviews = neg_reviews + \" \" + clean_review\n",
    "        neg_reviews =  re.sub('\\.\\s*\\.','.',neg_reviews)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textrank keywords in positive reviews:\n",
      "\n",
      "[('echo', 0.05026407489326626), ('technology', 0.031158594888747428), ('home', 0.03018813398510435), ('voice', 0.02609943712940595), ('little', 0.0235395483256734), ('dot', 0.02285831723855423), ('price', 0.02168527160554599), ('smart', 0.021372610574844957), ('great', 0.021308031859971172), ('alarm', 0.020927232561873396)]\n",
      "\n",
      "Textrank keywords in negative reviews:\n",
      "\n",
      "[('i.', 0.3667352990529791), ('m', 0.2459279727012903), ('trouble', 0.2459279727012903), ('sorry', 0.1414087555444403)]\n"
     ]
    }
   ],
   "source": [
    "#Create textacy doc of pos and negative reviews\n",
    "doc_pos = textacy.Doc(pos_reviews,lang=u'en_core_web_sm')\n",
    "doc_neg = textacy.Doc(neg_reviews,lang=u'en_core_web_sm')\n",
    "\n",
    "#textacy textranking\n",
    "print (\"Textrank keywords in positive reviews:\\n\")\n",
    "print (textacy.keyterms.textrank(doc_pos,normalize='lemma',n_keyterms=10))\n",
    "\n",
    "print (\"\\nTextrank keywords in negative reviews:\\n\")\n",
    "print (textacy.keyterms.textrank(doc_neg,normalize='lemma',n_keyterms=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Textacy bag of terms:\n",
      "\n",
      "[('echo', 396), ('echo dot', 297), ('-PRON- love', 297), ('big brother', 198), ('british', 99), ('ai', 99), ('first', 99), ('alexa', 99), ('smart technology', 99), ('need briefing', 99), ('work great', 99), ('-PRON- absolutely', 99), ('absolutely love', 99), ('be able', 99), ('play game', 99)]\n"
     ]
    }
   ],
   "source": [
    "#Textacy bag of terms with count weighting\n",
    "bot = doc_pos.to_bag_of_terms(ngrams=2, named_entities=True, \\\n",
    "                          weighting='count',as_strings=True)\n",
    "\n",
    "print (\"\\nTextacy bag of terms:\\n\")\n",
    "print(sorted(bot.items(), key=lambda x: x[1], reverse=True)[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Textacy POS matching:\n",
      "\n",
      "could do\n",
      "am addicted\n",
      "absolutely love\n",
      "even make\n",
      "have dreamed\n",
      "IS LISTENING\n",
      "not appreciate\n",
      "definitely enjoy\n",
      "HIGHLY recommend\n",
      "instantly converts\n",
      "be worked\n",
      "sits hidden\n",
      "is always playing\n",
      "could do\n",
      "am addicted\n",
      "absolutely love\n",
      "even make\n",
      "have dreamed\n",
      "IS LISTENING\n",
      "not appreciate\n",
      "definitely enjoy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#textacy pattern matching\n",
    "pattern = r'<VERB>?<ADV>*<VERB>+'\n",
    "matching_lists = textacy.extract.pos_regex_matches(doc_pos, pattern)\n",
    "\n",
    "#controls display count\n",
    "print_count = 20\n",
    "i=0\n",
    "\n",
    "print (\"\\nTextacy POS matching:\\n\")\n",
    "for list in matching_lists:\n",
    "    #Filter out single words\n",
    "    if re.match('[a-zA-Z]*\\s+[a-zA-Z]',list.text):\n",
    "        print(list.text)\n",
    "        i +=1\n",
    "    if (i > print_count) :\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
